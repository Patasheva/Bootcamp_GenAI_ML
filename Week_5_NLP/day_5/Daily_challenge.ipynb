{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/patash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/patash/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Text Summarization Using NLP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "df = pd.read_csv('/Users/patash/PSTB/Week_5_NLP/day_5/tennis_articles.csv', encoding='ISO-8859_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   article_id     8 non-null      int64 \n",
      " 1   article_title  8 non-null      object\n",
      " 2   article_text   8 non-null      object\n",
      " 3   source         8 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 388.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_id                                      article_title  \\\n",
      "0           1  I do not have friends in tennis, says Maria Sh...   \n",
      "1           2  Federer defeats Medvedev to advance to 14th Sw...   \n",
      "2           3  Tennis: Roger Federer ignored deadline set by ...   \n",
      "3           4  Nishikori to face off against Anderson in Vien...   \n",
      "4           5  Roger Federer has made this huge change to ten...   \n",
      "\n",
      "                                        article_text  \\\n",
      "0  Maria Sharapova has basically no friends as te...   \n",
      "1  BASEL, Switzerland (AP)  Roger Federer advanc...   \n",
      "2  Roger Federer has revealed that organisers of ...   \n",
      "3  Kei Nishikori will try to end his long losing ...   \n",
      "4  Federer, 37, first broke through on tour over ...   \n",
      "\n",
      "                                              source  \n",
      "0  https://www.tennisworldusa.org/tennis/news/Mar...  \n",
      "1  http://www.tennis.com/pro-game/2018/10/copil-s...  \n",
      "2  https://scroll.in/field/899938/tennis-roger-fe...  \n",
      "3  http://www.tennis.com/pro-game/2018/10/nishiko...  \n",
      "4  https://www.express.co.uk/sport/tennis/1036101...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 1 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_text  8 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 196.0+ bytes\n",
      "None\n",
      "                                        article_text\n",
      "0  Maria Sharapova has basically no friends as te...\n",
      "1  BASEL, Switzerland (AP)  Roger Federer advanc...\n",
      "2  Roger Federer has revealed that organisers of ...\n",
      "3  Kei Nishikori will try to end his long losing ...\n",
      "4  Federer, 37, first broke through on tour over ...\n"
     ]
    }
   ],
   "source": [
    "# Remove Unnecessary Columns\n",
    "df = df.drop(columns=['article_title', 'source', 'article_id'])\n",
    "\n",
    "print(df.info()) \n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maria Sharapova has basically no friends as tennis players on the WTA Tour.', \"The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.\", 'I think everyone knows this is my job here.', \"When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.\", \"So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\", \"I'm a pretty competitive girl.\", \"I say my hellos, but I'm not sending any players flowers as well.\", \"Uhm, I'm not really friendly or close to many players.\", \"I have not a lot of friends away from the courts.'\", 'When she said she is not really close to a lot of players, is that something strategic that she is doing?', \"Is it different on the men's tour than the women's tour?\", \"'No, not at all.\", \"I think just because you're in the same sport doesn't mean that you have to be friends with everyone just because you're categorized, you're a tennis player, so you're going to get along with tennis players.\", 'I think every person has different interests.', \"I have friends that have completely different jobs and interests, and I've met them in very different parts of my life.\", \"I think everyone just thinks because we're tennis players we should be the greatest of friends.\", 'But ultimately tennis is just a very small part of what we do.', \"There are so many other things that we're interested in, that we do.'\", 'ALSO READ: Maria Sharapova reveals how tennis keeps her motivated.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/patash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/patash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df_tokenized = df['article_text'].apply(nltk.sent_tokenize)\n",
    "print(df_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings: 400000it [00:06, 61240.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 words into embeddings.\n"
     ]
    }
   ],
   "source": [
    "# GloVe Word Embeddings\n",
    "# Load GloVe vectors \n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Barre de progression\n",
    "\n",
    "def load_glove_embeddings(file_path):\n",
    "    glove_embeddings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe embeddings\"):  # Affichage de la progression\n",
    "            values = line.strip().split()\n",
    "            word = values[0]  # Le mot\n",
    "            vector = np.array(values[1:], dtype='float32')  # Le vecteur\n",
    "            glove_embeddings[word] = vector\n",
    "    return glove_embeddings\n",
    "\n",
    "glove_embeddings = load_glove_embeddings('glove.6B.100d.txt')\n",
    "print(\"Loaded\", len(glove_embeddings), \"words into embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maria sharapova has basically no friends as tennis players on the wta tour\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/patash/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "\n",
    "  sentence = re.sub(r'[^\\w\\s]', '', sentence) # Ponctuation\n",
    "  sentence = re.sub(r'\\d+', '', sentence) # Chiffres\n",
    "  sentence = sentence.lower()\n",
    "  words = sentence.split()\n",
    "  words = [word for word in words if word not in stop_words]\n",
    "\n",
    "  return sentence\n",
    "\n",
    "sentences = df_tokenized.explode().tolist()\n",
    "\n",
    "cleaned_sentences = [clean_sentence(sentence) for sentence in sentences]\n",
    "print(cleaned_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize sentences: average of the word embeddings\n",
    "# Function to get sentence embedding\n",
    "def get_sentence_embedding(sentence):\n",
    "    words = sentence.split()  # Split cleaned sentence into words\n",
    "    word_vectors = [glove_embeddings[word] for word in words if word in glove_embeddings]  \n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(100)  # Return a zero vector if no words have embeddings\n",
    "    return np.mean(word_vectors, axis=0)  # Compute the average of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 100)\n"
     ]
    }
   ],
   "source": [
    "# Convert cleaned sentences into embeddings\n",
    "sentence_embeddings = np.array([get_sentence_embedding(sentence) for sentence in cleaned_sentences])\n",
    "\n",
    "print(sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001  0.8819135  0.8373998  ... 0.9248717  0.872359   0.81378967]\n",
      " [0.8819135  1.0000001  0.9307503  ... 0.896164   0.93493533 0.8766065 ]\n",
      " [0.8373998  0.9307503  1.0000001  ... 0.84453756 0.9069677  0.81943476]\n",
      " ...\n",
      " [0.9248717  0.896164   0.84453756 ... 0.99999976 0.8930172  0.8519911 ]\n",
      " [0.872359   0.93493533 0.9069677  ... 0.8930172  0.99999964 0.86473227]\n",
      " [0.81378967 0.8766065  0.81943476 ... 0.8519911  0.86473227 0.9999999 ]]\n",
      "(130, 130)\n"
     ]
    }
   ],
   "source": [
    "# Similarity Matrix \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "print(cos_similarity_matrix)\n",
    "print(cos_similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 130\n",
      "Total Edges: 8001\n"
     ]
    }
   ],
   "source": [
    "# Graph Construction\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (each sentence is a node)\n",
    "for i, sentence in enumerate(cleaned_sentences):\n",
    "    G.add_node(i, text=sentence)\n",
    "\n",
    "# Define similarity threshold (higher = fewer edges)\n",
    "threshold = 0.75\n",
    "\n",
    " # Add edges based on cos_similarity_matrix\n",
    "for i in range(len(cleaned_sentences)):\n",
    "    for j in range(i + 1, len(cleaned_sentences)):  # Avoid duplicate pairs\n",
    "        if cos_similarity_matrix[i][j] > threshold:  # Use your existing similarity matrix\n",
    "            G.add_edge(i, j, weight=cos_similarity_matrix[i][j])  # Edge with similarity score\n",
    "\n",
    "print(f\"Total Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Total Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top Ranked Sentences (by PageRank Score):\n",
      "1. (Score: 0.0082) - so im not the one to strike up a conversation about the weather and know that in the next few minutes i have to go and try to win a tennis match\n",
      "2. (Score: 0.0082) - i was on a nice trajectorythen reid recalledif i hadnt got sick i think i could have started pushing towards the second week at the slams and then who knows duringa comeback attempt some five years later reid added bernard tomic and  us open federer slayer john millman to his list of career scalps\n",
      "3. (Score: 0.0082) - i just felt like it really kind of changed where people were a little bit definitely in the s a lot more quiet into themselves and then it started to become better meanwhile federer is hoping he can improve his service game as he hunts his ninth swiss indoors title this week\n",
      "4. (Score: 0.0082) - speaking at the swiss indoors tournament where he will play in sundays final against romanian qualifier marius copil the world number three said that given the impossibly short time frame to make a decision he opted out of any commitment\n",
      "5. (Score: 0.0081) - major players feel that a big event in late november combined with one in january before the australian open will mean too much tennis and too little rest\n"
     ]
    }
   ],
   "source": [
    "# Sentence Ranking \n",
    "# Apply PageRank algorithm to rank sentences based on importance\n",
    "sentence_scores = nx.pagerank(G, alpha=0.85,  weight='weight')\n",
    "\n",
    "# Convert scores into a sorted list (higher score = more important)\n",
    "sorted_sentences = sorted(sentence_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top-ranked sentences (optional)\n",
    "print(\"\\n Top Ranked Sentences (by PageRank Score):\")\n",
    "for i, (idx, score) in enumerate(sorted_sentences[:5]):  # Displaying top 5 sentences\n",
    "    print(f\"{i+1}. (Score: {score:.4f}) - {cleaned_sentences[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so im not the one to strike up a conversation about the weather and know that in the next few minutes i have to go and try to win a tennis match i was on a nice trajectorythen reid recalledif i hadnt got sick i think i could have started pushing towards the second week at the slams and then who knows duringa comeback attempt some five years later reid added bernard tomic and  us open federer slayer john millman to his list of career scalps i just felt like it really kind of changed where people were a little bit definitely in the s a lot more quiet into themselves and then it started to become better meanwhile federer is hoping he can improve his service game as he hunts his ninth swiss indoors title this week\n"
     ]
    }
   ],
   "source": [
    "# Summarization\n",
    "\n",
    "N = 3\n",
    "top_sentences = [cleaned_sentences[idx] for idx, _ in sorted_sentences[:N]]\n",
    "\n",
    "# Step 4: Print Final Summary\n",
    "print(\" \".join(top_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
